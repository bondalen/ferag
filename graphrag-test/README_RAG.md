# Минимальный RAG по графу ferag-prod

Краткое описание скриптов и способа запуска (план 26-0213-1049). Подробности — в [docs/chats/26-0213-1049_plan.md](../docs/chats/26-0213-1049_plan.md).

## Запуск

**Требования:** Fuseki с датасетом ferag-prod, venv-graphrag (или окружение с `requests` и `openai`), LM Studio с загруженной моделью и Serve on Local Network. Если в venv нет `openai`: в активированном venv-graphrag выполнить `pip install openai`.

```bash
cd ~/projects/ferag
source venv-graphrag/bin/activate
cd graphrag-test
python rag_chat.py "Кто такой Alice Smith?"
```

Интерактивный ввод вопроса (если не передан аргументом):

```bash
python rag_chat.py --interactive
```

## Какой контекст используется

**По умолчанию — вариант A (контекст по вопросу):** ключевые слова из вопроса → SPARQL по сущностям и связям → сборка контекста в формате 1.1.1; при пустой выборке — fallback на фиксированную выборку. Флаг `--fixed` принудительно включает **вариант B (фиксированная выборка):** первые 15 сущностей и 15 связей из ferag-prod. Формат: секции «Сущности» и «Связи» в виде текста для промпта LLM.

## Ограничения первой версии

- Нет привязки контекста к словам вопроса: выборка фиксированная (первые 15+15). Вопрос о сущности, не попавшей в эту выборку, может не получить релевантный контекст.
- Нет семантического поиска по вопросу; улучшение — вариант A (1.2.x) в плане.
- Один запрос — один ответ; истории диалога нет.
- Контекст и модель: см. `rag_context.py` (Fuseki, датасет ferag-prod), `rag_llm.py` (LM Studio, base_url, модель).
