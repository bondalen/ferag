# Чат 4 — История диалога по RAG и контекст в LLM

**Дата:** 2026-02-22  
**Предшественник:** [26-0219-2034_plan.md](26-0219-2034_plan.md) (frontend + деплой; финальная проверка пройдена).  
**Источник последовательности:** [docs/project/PROJECT-004-chat-dialogue.md](../project/PROJECT-004-chat-dialogue.md), задачи 9.11–9.13 в [TASKS.md](../tasks/TASKS.md).

---

## Исходное состояние

- **Чат по RAG:** один вопрос → контекст из Fuseki → один ответ LLM. История не сохраняется: на фронте сообщения только в `ref`, после перезагрузки диалог пустой; в БД записей чата нет.
- **Backend** `POST /rags/{id}/chat`: принимает `question`, возвращает `answer` и `context_used`; вызов в БД не пишется.
- **Frontend** `ChatView.vue`: после ответа пушит в локальный `messages`; при открытии страницы история не подгружается.
- **rag_llm:** только `answer_from_context(context, question)` — один user-message, без формата «диалог».

---

## Задача плана (один чат)

Реализовать **первый шаг** согласованной последовательности: сохранение истории диалога в БД и отображение её на экране. Логику LLM не менять: модель по-прежнему получает только текущий вопрос + RAG-контекст.

**По возможности в том же чате:** второй шаг — передача последних K пар (скользящее окно) в LLM, чтобы модель учитывала предыдущие реплики. Если времени не хватит — вынести в следующий чат.

---

## Исходное состояние (файлы)

- `code/backend/app/models.py` — моделей для чата нет; есть User, RAG, UploadCycle, Task, RagMember.
- `code/backend/app/routers/rags.py` — эндпоинт `POST /rags/{rag_id}/chat`; нет записи в БД, нет `GET /rags/{rag_id}/chat/messages`.
- `code/frontend/src/views/ChatView.vue` — при открытии не запрашивает историю; `messages` только локальный ref.
- `code/frontend/src/api/chat.ts` — только `sendQuestion(ragId, question)`; нет функции загрузки сообщений.

---

## Шаги

### 1. Миграция: таблица `chat_messages`

В БД приложения (ferag_app) добавить таблицу:

- **chat_messages**  
  - `id` (PK), `rag_id` (FK → rags), `user_id` (FK → users), `role` (user | assistant), `content` (TEXT), `context_used` (INT, nullable — только для assistant), `created_at` (TIMESTAMP WITH TIME ZONE).

Ограничения: доступ к сообщениям только в рамках RAG, к которому у пользователя есть доступ (владелец или участник). При необходимости позже добавить `session_id` для разделения диалогов.

**Действия:** добавить модель в `code/backend/app/models.py`; сгенерировать миграцию Alembic; применить `alembic upgrade head`.

---

### 2. Backend: запись истории при ответе и эндпоинт получения сообщений

**2.1** В обработчике `POST /rags/{rag_id}/chat` после успешного ответа LLM:
- Создать запись `ChatMessage(rag_id, user_id=current_user.id, role='user', content=body.question, context_used=None, created_at=...)`.
- Создать запись `ChatMessage(..., role='assistant', content=answer, context_used=context_used, ...)`.
- Выполнить `db.commit()`.

**2.2** Добавить эндпоинт `GET /rags/{rag_id}/chat/messages`:
- Проверка доступа: `_can_access_rag` (владелец или участник).
- Параметры запроса: опционально `limit` (по умолчанию 50), `offset` (0).
- Возвращать список сообщений в хронологическом порядке (старые сверху): `{ id, role, content, context_used, created_at }`.
- Модель ответа: например `ChatMessageListItem` или список в обёртке.

---

### 3. Frontend: загрузка истории при открытии диалога

**3.1** В `code/frontend/src/api/chat.ts`:
- Добавить интерфейс для элемента сообщения (role, content, context_used?, created_at?).
- Добавить функцию `getChatMessages(ragId: number, limit?: number, offset?: number): Promise<...>` — вызов `GET /rags/{ragId}/chat/messages`.

**3.2** В `ChatView.vue`:
- При открытии страницы (например в `onMounted`) вызывать `getChatMessages(ragId)` и заполнять `messages` полученными данными.
- После успешной отправки вопроса и получения ответа новую пару (user + assistant) по-прежнему добавлять в `messages` локально (ответ уже приходит с бэкенда; запись в БД делает backend). При желании можно после ответа не вызывать повторно `getChatMessages`, а только дописывать два элемента в массив.

Итог: при переходе в «Диалог» пользователь видит сохранённую историю; после отправки нового вопроса история обновляется (локально + в БД на бэкенде).

---

### 4. (По возможности) Скользящее окно: передача последних K пар в LLM

**4.1** В `POST /rags/{rag_id}/chat` перед вызовом RAG и LLM:
- Загрузить из БД последние 2K сообщений по данному `rag_id` и `current_user.id` (или без user_id, если история общая на RAG), где K = 3–5 (константа или настройка).
- Преобразовать в список словарей `{ "role": "user"|"assistant", "content": "..." }` в порядке возрастания `created_at`.

**4.2** В `code/backend/rag_llm.py`:
- Добавить функцию `answer_from_context_with_history(rag_context: str, messages: list[dict], current_question: str, ...)` (или принимать уже собранный список `messages` с последним user-message, включающим RAG-контекст и вопрос).
- Формировать вызов Chat API: `messages=[ system (инструкция + опционально RAG-контекст), ...предыдущие пары, user (текущий вопрос + RAG-контекст) ]`.
- Использовать `client.chat.completions.create(..., messages=...)` вместо одного user-message.

**4.3** В роутере `chat`: если загружены последние K пар, вызывать `answer_from_context_with_history`; иначе (пустая история) — текущую логику `answer_from_context`. После ответа по-прежнему писать две записи в `chat_messages`.

Итог: модель получает последние 3–5 пар вопрос–ответ и текущий вопрос, ответы становятся связными и учитывают уточнения.

---

## Критерии успеха

- После выполнения шагов 1–3:
  - Пользователь открывает «Диалог» по RAG → видит ранее сохранённые реплики (если были).
  - Отправляет новый вопрос → получает ответ; после перезагрузки страницы эта пара отображается в истории.
  - В БД в таблице `chat_messages` появляются записи с `role` user/assistant для данного RAG и пользователя.

- После выполнения шага 4 (если сделан):
  - Уточняющий вопрос («а что насчёт X?») получает ответ с учётом предыдущих реплик (модель «помнит» контекст диалога).

---

## Вне объёма данного чата

- Сжатие длинных диалогов (резюме, периодическая суммаризация) — задача 9.13, следующий чат или отдельный план.
- Сессии диалога (session_id), лимит по токенам для старых реплик — по желанию позже.

---

## Ссылки

- [PROJECT-004-chat-dialogue](../project/PROJECT-004-chat-dialogue.md) — архитектура диалога, порядок действий, сжатие
- [PROJECT-004](PROJECT-004.md) — п. 9 «Диалог по RAG (чат): порядок работы»
- [TASKS.md](../tasks/TASKS.md) — 9.11, 9.12, 9.13
