# Чат 2 — Worker + полный цикл обновления RAG

**Дата:** 2026-02-19 (план подготовлен в конце Чата 1)  
**Предшественник:** [26-0218-1703_plan.md](26-0218-1703_plan.md) (backend skeleton, все критерии Чата 1 выполнены).

---

## Исходное состояние

- **Backend**: FastAPI работает; auth (`/auth/register`, `/auth/login`, `/auth/me`), rags (`/rags`), tasks (`/tasks/{id}`, `/rags/{id}/tasks`) протестированы.
- **БД**: 5 таблиц (users, rag_instances, rag_members, upload_cycles, tasks); Alembic migration применена.
- **Fuseki**: запущен на `localhost:43030`; `create_dataset` / `delete_dataset` работают.
- **code/worker/**: не реализован; Dockerfile не существует; `docker compose up worker` упадёт.
- **graphrag-test/**: рабочий pipeline в виде standalone-скриптов (`test_graphrag_to_rdf.py`, `test_schema_induction.py`, `merge_ontologies.py`, `merge_triples.py`); все функции завёрнуты в `main()` — не импортируемы напрямую.
- **Redis**: отсутствует на nb-win; нужен для Celery broker и WebSocket pub/sub.

---

## Задача плана

1. Добавить Redis в `deploy/nb-win/docker-compose.yml`.
2. Реализовать `code/worker/` — Celery-приложение с цепочкой задач.
3. Адаптировать скрипты `graphrag-test/` для программного вызова (`graphrag_lib`).
4. Расширить backend: `POST /rags/{id}/upload`, WebSocket `/ws/tasks/{id}`, `POST /rags/{id}/cycles/{id}/approve`.
5. Новый роутер `/rags/{id}/chat` — RAG-вопрос к prod-датасету через LLM.
6. Финальная проверка: upload → WebSocket → approve → chat.

---

## Исходное состояние (файлы и сервисы)

```
ferag/
├── code/
│   ├── backend/           # Готово (Чат 1)
│   └── worker/            # ❌ Не существует
├── graphrag-test/         # Скрипты pipeline (нужна адаптация)
└── deploy/
    └── nb-win/
        └── docker-compose.yml   # Нужно добавить redis
```

**Сервисы перед началом:**

| Сервис      | Статус         | Порт           |
|-------------|----------------|----------------|
| PostgreSQL  | ✅ запущен      | localhost:45432 |
| Fuseki      | ✅ запущен      | localhost:43030 |
| Redis       | ❌ нет          | —              |
| LM Studio   | ⚡ нужен для LLM | Windows:41234  |
| WireGuard   | ⚡ нужен для Redis cr-ubu | — |

---

## Соглашения

### Рабочие каталоги задач
Каждый цикл обновления работает в изолированном каталоге:
```
/tmp/ferag/rag_{rag_id}/cycle_{cycle_id}/
├── input/
│   └── source.txt          # Загруженный файл
├── output/                 # Результаты GraphRAG (parquet)
├── graphrag_output.ttl     # RDF из GraphRAG
├── extracted_ontology.ttl  # Schema Induction
├── integrated_ontology.ttl # После merge_ontologies
└── integrated_triples.ttl  # После merge_triples
```

### Redis channels
- `task:{task_id}` — pub/sub для WebSocket статусов
- Сообщения: `{"status": "running|done|failed", "step": "graphrag|schema|merge_onto|merge_triples|staging", "error": null}`

### Именование Fuseki датасетов (уже в fuseki_admin.py)
| Функция                          | Датасет              |
|----------------------------------|----------------------|
| `rag_prod_dataset(rag_id)`       | `ferag-{id:05d}`     |
| `rag_staging_dataset(rag_id)`    | `ferag-{id:05d}-stg` |
| `rag_triples_dataset(rag_id)`    | `ferag-{id:05d}-tri` |
| `rag_ontology_dataset(rag_id)`   | `ferag-{id:05d}-ont` |

### Celery broker/backend
```
CELERY_BROKER_URL=redis://localhost:47379/0   # nb-win локально
                  redis://10.7.0.1:47379/0   # через WireGuard (prod)
CELERY_RESULT_BACKEND=redis://localhost:47379/1
```

---

## Шаги

### 1. Среда: Redis + структура worker

#### 1.1 Добавить Redis в `deploy/nb-win/docker-compose.yml`

Добавить сервис `redis` на порту 47379 (слушать на `127.0.0.1` для WSL2-доступа).

```yaml
redis:
  image: redis:7-alpine
  container_name: ferag-redis
  restart: unless-stopped
  command: redis-server --port 47379 --appendonly yes --dir /data
  ports:
    - "127.0.0.1:47379:47379"
  volumes:
    - redis-data:/data
  networks:
    - ferag-network
```

Добавить `redis-data` в секцию `volumes`.

Запустить: `docker compose up -d redis`  
Проверка: `redis-cli -p 47379 ping` → `PONG`

#### 1.2 Создать структуру `code/worker/`

```
code/worker/
├── Dockerfile
├── requirements.txt
├── celery_app.py
├── config.py
├── fuseki_client.py       # Обёртка над SPARQL/Fuseki (из backend)
└── tasks/
    ├── __init__.py
    ├── base.py            # Базовый класс с update_task_status()
    ├── graphrag_task.py
    ├── schema_task.py
    ├── merge_task.py
    └── staging_task.py
```

#### 1.3 `code/worker/requirements.txt`

```
celery[redis]
redis
sqlalchemy
psycopg2-binary
httpx
graphrag          # MS GraphRAG
llama-index-core
llama-index-llms-openai-like
rdflib
python-dotenv
pydantic-settings
```

#### 1.4 `code/worker/config.py`

Аналогично backend: `pydantic_settings.BaseSettings`, загрузка из `.env`:
- `celery_broker_url`, `celery_result_backend`
- `database_url`
- `fuseki_url`, `fuseki_user`, `fuseki_password`
- `llm_api_url` (LM Studio или OpenAI-совместимый)
- `llm_model` (имя модели, e.g. `lmstudio-community/Meta-Llama-3.3-70B-Instruct-UDLQ4_K_M`)
- `work_dir` = `/tmp/ferag` (базовый каталог рабочих файлов)

#### 1.5 `code/worker/celery_app.py`

```python
from celery import Celery
from worker.config import get_settings  # или config напрямую

settings = get_settings()

celery = Celery(
    "ferag_worker",
    broker=settings.celery_broker_url,
    backend=settings.celery_result_backend,
    include=[
        "tasks.graphrag_task",
        "tasks.schema_task",
        "tasks.merge_task",
        "tasks.staging_task",
    ],
)

celery.conf.update(task_serializer="json", result_serializer="json")
```

#### 1.6 `code/worker/Dockerfile`

```dockerfile
FROM python:3.11-slim

RUN apt-get update && apt-get install -y \
    build-essential curl \
    && rm -rf /var/lib/apt/lists/*

WORKDIR /app

COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY . /app/worker

# graphrag-test монтируется как том (см. docker-compose.yml)
ENV PYTHONPATH=/app:/app/graphrag-test

CMD ["celery", "-A", "worker.celery_app:celery", "worker", "--loglevel=info", "--concurrency=2"]
```

Проверка: `docker compose build worker` без ошибок.

---

### 2. Адаптация `graphrag-test/` как библиотеки

#### 2.1 Проанализировать скрипты-кандидаты

Каждый скрипт имеет `main()`. Для программного вызова нужно вынести логику в функции с параметрами:

| Скрипт                    | Функция-цель                             | Вход                        | Выход                         |
|---------------------------|------------------------------------------|-----------------------------|-------------------------------|
| `test_graphrag_to_rdf.py` | `graphrag_to_rdf(root_dir) -> Path`      | путь к output/ GraphRAG     | `graphrag_output.ttl`         |
| `test_schema_induction.py`| `run_schema_induction(root_dir, llm_cfg) -> Path` | output/ + LLM cfg | `extracted_ontology.ttl`      |
| `merge_ontologies.py`     | `merge_ontologies(onto1, onto2) -> Path` | 2 TTL файла                 | `integrated_ontology.ttl`     |
| `merge_triples.py`        | `merge_triples(triples1, triples2) -> Path` | 2 TTL файла              | `integrated_triples.ttl`      |

Стратегия: **не менять оригинальные скрипты**. Создать `graphrag_lib/` прямо в `graphrag-test/` (или отдельный пакет) с тонкими обёртками, которые импортируют нужные функции из скриптов (после добавления `/app/graphrag-test` в `sys.path`).

#### 2.2 Создать `graphrag-test/graphrag_lib/__init__.py`

Экспортировать: `run_graphrag_pipeline`, `run_schema_induction`, `merge_ontologies`, `merge_triples`.

Каждая функция:
- Получает рабочий каталог цикла (`work_dir: Path`)
- Выполняет логику (через import или subprocess при необходимости)
- Возвращает путь к артефакту
- При ошибке — бросает исключение с понятным сообщением

Проверка: `python -c "from graphrag_lib import run_graphrag_pipeline; print('ok')"` из `graphrag-test/`.

---

### 3. Celery задачи

#### 3.1 `tasks/base.py` — вспомогательные функции

```python
import redis
from sqlalchemy import create_engine
from sqlalchemy.orm import Session

def get_db_session() -> Session: ...          # создаёт сессию по DATABASE_URL
def publish_status(r, task_id, status, step, error=None): ...  # r.publish(f"task:{task_id}", json)
def update_task(db, task_id, status, error=None): ...           # обновляет Task в БД
```

#### 3.2 `tasks/graphrag_task.py` — `run_graphrag`

```python
@celery.task(bind=True)
def run_graphrag(self, rag_id: int, cycle_id: int, task_id: int, input_file: str):
    # 1. Подготовить work_dir/input/source.txt
    # 2. Создать settings.yaml для этого запуска (шаблон из graphrag-test/settings.yaml,
    #    с заменой путей input/output на work_dir)
    # 3. graphrag index --root work_dir
    # 4. graphrag_lib.run_graphrag_pipeline(work_dir) → graphrag_output.ttl
    # 5. update_task + publish_status
```

Задача долгая (5–30 минут). `task_time_limit=3600`.

#### 3.3 `tasks/schema_task.py` — `run_schema_induction`

```python
@celery.task(bind=True)
def run_schema_induction(self, rag_id: int, cycle_id: int, task_id: int):
    # graphrag_lib.run_schema_induction(work_dir, llm_cfg) → extracted_ontology.ttl
    # update + publish
```

#### 3.4 `tasks/merge_task.py` — `merge_ontologies`, `merge_triples`

```python
@celery.task(bind=True)
def do_merge(self, rag_id: int, cycle_id: int, task_id: int):
    # Скачать prod-онтологию из Fuseki (-ont dataset) в prod_ontology.ttl
    # graphrag_lib.merge_ontologies(extracted, prod_onto) → integrated_ontology.ttl
    # Скачать prod-триплеты из Fuseki (prod dataset) в prod_triples.ttl
    # graphrag_lib.merge_triples(graphrag_output, prod_triples) → integrated_triples.ttl
    # update + publish
```

#### 3.5 `tasks/staging_task.py` — `load_to_staging`

```python
@celery.task(bind=True)
def load_to_staging(self, rag_id: int, cycle_id: int, task_id: int):
    # create_dataset(rag_triples_dataset(rag_id))
    # create_dataset(rag_ontology_dataset(rag_id))
    # create_dataset(rag_staging_dataset(rag_id))
    # SPARQL UPDATE: загрузить integrated_triples.ttl → -tri
    # SPARQL UPDATE: загрузить integrated_ontology.ttl → -ont
    # (staging = виртуальный union; или загрузить в -stg = объединение -tri + -ont)
    # db: UploadCycle.status = 'ready'
    # db: Task.status = 'done'
    # publish {"status": "done", "step": "staging"}
```

#### 3.6 Цепочка задач — сборка chain

В `tasks/__init__.py` или отдельном модуле:

```python
from celery import chain

def start_update_chain(rag_id, cycle_id, task_id, input_file):
    return chain(
        run_graphrag.s(rag_id, cycle_id, task_id, input_file),
        run_schema_induction.s(rag_id, cycle_id, task_id),
        do_merge.s(rag_id, cycle_id, task_id),
        load_to_staging.s(rag_id, cycle_id, task_id),
    ).apply_async()
```

Ошибка в любом шаге: `on_failure` callback → `Task.status = 'failed'`, publish error.

---

### 4. Backend: новые эндпоинты

#### 4.1 `POST /rags/{rag_id}/upload`

```python
@router.post("/{rag_id}/upload")
async def upload_file(rag_id: int, file: UploadFile = File(...),
                      db: Session = Depends(get_db),
                      current_user: User = Depends(get_current_user)):
    rag = _can_access_rag(db, current_user, rag_id)
    # Сохранить файл в /tmp/ferag/rag_{rag_id}/cycle_{cycle_id}/input/source.txt
    # Создать UploadCycle (status='pending')
    # Создать Task (type='full_cycle', status='running')
    # start_update_chain.delay(rag_id, cycle.id, task.id, file_path)
    return {"cycle_id": cycle.id, "task_id": task.id}
```

Ограничения: только owner может загружать; Content-Type: text/plain или .txt.

#### 4.2 WebSocket `/ws/tasks/{task_id}`

Добавить в `main.py`:
```python
from fastapi import WebSocket
from app.deps import get_current_user_ws   # новая зависимость: token из query param

@app.websocket("/ws/tasks/{task_id}")
async def ws_task_status(websocket: WebSocket, task_id: int, token: str):
    # Аутентифицировать token
    # Проверить доступ к task
    # Подписаться на Redis channel f"task:{task_id}"
    # Стримить сообщения клиенту
    # Закрыть при status == "done" или "failed"
```

Для async Redis подписки: `redis.asyncio` (входит в `redis[asyncio]`).

Добавить в `requirements.txt` backend: `redis[asyncio]` (уже есть `redis` как dep Celery, убедиться в наличии asyncio extra).

#### 4.3 `POST /rags/{rag_id}/cycles/{cycle_id}/approve`

```python
@router.post("/{rag_id}/cycles/{cycle_id}/approve")
def approve_cycle(rag_id: int, cycle_id: int, ...):
    # Проверить owner
    # Проверить cycle.status == 'ready'
    # SPARQL COPY: скопировать содержимое -stg → в prod dataset (-prod)
    #   (через fuseki_admin: DELETE всех триплетов в prod, INSERT из stg)
    # Удалить датасеты: -tri, -ont, -stg
    # UploadCycle.status = 'approved'
    # RagInstance.cycle_count += 1
    # Вернуть 200 {message: "approved"}
```

#### 4.4 `GET /rags/{rag_id}/chat` — RAG-вопрос

```python
class ChatRequest(BaseModel):
    question: str

@router.post("/{rag_id}/chat")
def chat(rag_id: int, body: ChatRequest, ...):
    # _can_access_rag
    # rag_context.build_context_a(question, dataset=rag.fuseki_dataset)
    #   — переиспользовать логику из graphrag-test/rag_context.py
    # rag_llm.ask_llm(context, question)
    #   — переиспользовать из graphrag-test/rag_llm.py
    # Вернуть {answer: str, context_used: int}
```

Зависимость: `graphrag-test/` должна быть на `sys.path` backend или иметь установленный пакет `graphrag_lib`. Для dev: добавить `sys.path.insert(0, "../../graphrag-test")` в `main.py` или конфигурацию.

---

### 5. Alembic миграция

Поля `UploadCycle` и `Task` уже в моделях. Проверить, нет ли незамигрированных изменений. Если нет новых полей — миграция не нужна.

---

### 6. Финальная проверка

Сценарий:
1. `docker compose up -d redis` — Redis поднят.
2. `docker compose up -d worker` — Worker поднят.
3. `POST /auth/login` → token.
4. `POST /rags` → rag_id.
5. `POST /rags/{id}/upload` (файл `graphrag-test/input/source.txt`) → `{cycle_id, task_id}`.
6. WebSocket `ws://localhost:47821/ws/tasks/{task_id}?token=...` — получить статусы шагов.
7. Дождаться `{"status": "done"}`.
8. `POST /rags/{id}/cycles/{cycle_id}/approve` → 200.
9. Fuseki: датасет `ferag-{id:05d}` содержит триплеты.
10. `POST /rags/{id}/chat` с вопросом → LLM-ответ.

---

## Критерии успеха (Чат 2)

- `docker compose up -d redis worker` запускается без ошибок.
- `POST /rags/{id}/upload` возвращает `{cycle_id, task_id}`.
- WebSocket `/ws/tasks/{id}` стримит статусы всех шагов (5 шагов).
- После approve: `GET /rags/{id}` → `cycle_count == 1`.
- После approve: датасет `ferag-{id:05d}` содержит триплеты из загруженного файла (проверить через Fuseki SPARQL).
- `POST /rags/{id}/chat` → ответ LLM, не пустой.

---

## Вне объёма данного плана

- Управление участниками (`POST /rags/{id}/members`) — Чат 3.
- Frontend (Vue 3) — Чат 3.
- Docker-деплой на cr-ubu — Чат 3.
- `code/backend/Dockerfile` + supervisord — Чат 3.

---

## Контур следующих чатов

### Чат 3 — Frontend (Vue) + деплой

(описан в [26-0218-1703_plan.md](26-0218-1703_plan.md), раздел «Чат 3»)

---

## Ссылки

- Архитектура: [docs/project/PROJECT-004.md](../project/PROJECT-004.md)
- Задачи: [docs/tasks/TASKS.md](../tasks/TASKS.md) (Блок 9, задачи 9.2–9.5)
- Docker: [deploy/nb-win/docker-compose.yml](../../deploy/nb-win/docker-compose.yml)
- Предшественник: [26-0218-1703_plan.md](26-0218-1703_plan.md)
- Лабораторный pipeline: [graphrag-test/README_RAG.md](../../graphrag-test/README_RAG.md)
