# План: вариант A — привязка контекста к словам вопроса (1.2.x)

**Дата:** 2026-02-15, 16:00  
**Цель:** Реализовать выборку контекста из ferag-prod по словам вопроса (вариант A) с fallback на фиксированную выборку.  
**Предшественник:** [26-0213-1049_plan.md](26-0213-1049_plan.md) (минимальный RAG достигнут; резюме: [26-0213-1049_plan_resume.md](26-0213-1049_plan_resume.md)).

---

## Исходное состояние

- Минимальный RAG работает: `rag_chat.py` использует фиксированную выборку контекста (15 сущностей, 15 связей) из `rag_context.build_context_fixed()`.
- Ограничение: при вопросе о сущности, не входящей в первые 15 по алфавиту, релевантный контекст может не попасть в промпт.
- Вариант A из плана 26-0213-1049 (пункты 1.2.1–1.2.5) не реализован.

---

## Задача плана

Реализовать **вариант A**: извлечение ключевых слов из вопроса → SPARQL-запросы с фильтрацией по этим словам (сущности и связи) → сборка контекста в том же формате, что в 1.1.1. При пустой выборке — **fallback** на `build_context_fixed()`. Интегрировать в `rag_chat.py` (переключение режима или замена вызова контекста по умолчанию).

---

## Шаги

### ✅ 1.2.1 Извлечение ключевых слов из вопроса

- Вход: строка вопроса. Выход: список слов (токенов).
- Эвристика: разбиение по пробелам и знакам пунктуации, приведение к нижнему регистру, опционально — отброс стоп-слов (короткий список для русского/английского: «кто», «что», «где», «как», «the», «a», «is» и т.п.).
- Реализация: функция в `rag_context.py` (или отдельный модуль). Проверка: на примерах «Кто такой Alice Smith?», «Где работает Bob Johnson?» убедиться, что в списке есть «alice», «smith», «bob», «johnson» и т.д.  
  **Результат:** в `rag_context.py` добавлены константа `STOP_WORDS` (RU/EN) и функция `extract_keywords(question)`: разбиение через `re.findall(r"[^\s\W]+", ...)`, нижний регистр, отброс стоп-слов и токенов короче 2 символов. Проверка пройдена: «Кто такой Alice Smith?» → `['alice', 'smith']`, «Где работает Bob Johnson?» → `['bob', 'johnson']`, «Что такое DataCorp?» → `['datacorp']`. При запуске `python rag_context.py` выводится блок проверки 1.2.1.

### ✅ 1.2.2 SPARQL: сущности по совпадению с вопросом

- Запрос к ferag-prod: сущности из `ferag#` с `rdf:type` и опционально `ferag:description`, где **в описании или в локальном имени** сущности встречается хотя бы одно слово из списка 1.2.1.
- Реализация: `FILTER CONTAINS(LCASE(?x), ?word)` или `REGEX` с учётом возможностей Fuseki; для имени сущности — разбить URI на локальную часть и сравнивать. Лимит 15–20.
- Функция: `fetch_entities_by_keywords(keywords: list[str], limit=20)` в `rag_context.py`. Проверка: вопрос «Что такое DataCorp?» — в выборке есть сущность DataCorp (если есть в графе).  
  **Результат:** добавлены шаблон `ENTITIES_BY_KEYWORDS_QUERY` и функция `fetch_entities_by_keywords(keywords, limit=20)` в `rag_context.py`. Фильтр: `CONTAINS(LCASE(STR(?s)), word)` по URI и по `?desc` при `BOUND(?desc)`; подстановка слов с экранированием `_sparql_str_escape`. Проверка: для ключевых слов `['datacorp']` в выборке присутствует сущность DATACORP (и при необходимости другие совпадения по описанию). При запуске `python rag_context.py` выводится блок проверки 1.2.2.

### ✅ 1.2.3 SPARQL: связи, релевантные вопросу

- Вариант 1: связи, у которых `from` или `to` входят в множество сущностей из 1.2.2.
- Вариант 2: связи, в чьём `ferag:description` встречается любое из слов вопроса (FILTER CONTAINS/REGEX). Лимит 15.
- Рекомендация: комбинировать (сначала связи по сущностям из 1.2.2, при необходимости дополнять по описанию). Функция: `fetch_relationships_by_keywords(keywords)` или по множеству URI сущностей. Проверка: для вопроса про Alice Smith в выборке связей есть связи с ALICE_SMITH.  
  **Результат:** в `rag_context.py` добавлены шаблоны `RELATIONSHIPS_BY_ENTITIES_QUERY` и `RELATIONSHIPS_BY_DESC_QUERY`; функции `fetch_relationships_by_entity_names(entity_names, limit)` (фильтр по локальному имени: `REPLACE(STR(?from), "^.*#", "") IN (...)` и то же для `?to`), `fetch_relationships_by_description_keywords(keywords, limit)` (CONTAINS по описанию) и объединяющая `fetch_relationships_for_question(entities, keywords, limit)`: сначала связи по сущностям, затем дополнение по словам в описании с дедупликацией по (from_name, to_name). Проверка: для сущностей по [alice, smith] в выборке связей есть связи с ALICE_SMITH. При запуске `python rag_context.py` выводится блок проверки 1.2.3.

### ✅ 1.2.4 Интеграция и fallback (вариант A)

- Функция `build_context_by_question(question: str) -> str`: 1.2.1 (слова) → 1.2.2 и 1.2.3 (запросы) → сборка текстового контекста в формате 1.1.1. Если результат пустой (0 сущностей и 0 связей) — вызвать `build_context_fixed()` и вернуть его результат.
- Проверка: вопрос с совпадениями в графе — контекст содержит релевантные сущности/связи; вопрос без совпадений или пустой — fallback даёт фиксированную выборку.  
  **Результат:** в `rag_context.py` добавлены `_format_context(entities, relationships)` (общая сборка в формате 1.1.1) и `build_context_by_question(question)`: ключевые слова → сущности и связи по вопросу → при пустой выборке вызов `build_context_fixed()`. В `rag_chat.py` по умолчанию используется `build_context_by_question(question)`, флаг `--fixed` включает фиксированную выборку. Перед вызовом LLM выводится предупреждение в stderr: «Сейчас будет вызван LLM (LM Studio). Убедитесь, что модель запущена и доступна.» Проверка: для «Кто такой Alice Smith?» контекст содержит ALICE_SMITH; для «абракадабра» — fallback, фиксированная выборка.

### ✅ 1.2.5 Проверка варианта A

- Запуск `rag_chat.py` с вопросами «Кто такой Alice Smith?», «Где работает Bob Johnson?», «Что такое DataCorp?» (или другой сущности вне первых 15 по алфавиту). Убедиться, что контекст релевантен и ответ опирается на граф. При вопросе «абракадабра» — fallback, ответ возможен по общему контексту.  
  **Результат:** в `rag_context.py` в `main()` добавлен блок проверки 1.2.5: для трёх вопросов строится контекст и проверяется наличие ожидаемой сущности (ALICE_SMITH, BOB_JOHNSON, DATACORP); для «абракадабра» проверяется fallback (фиксированная выборка). Все проверки пройдены. Проверку того, что ответ LLM опирается на граф, выполняют вручную: запуск `python rag_chat.py "Кто такой Alice Smith?"` при работающем LM Studio и просмотр ответа.

### ✅ Интеграция в rag_chat.py

- Заменить вызов `build_context_fixed()` на `build_context_by_question(question)` (или добавить флаг `--fixed` для принудительного использования варианта B). Обновить README_RAG.md: контекст по умолчанию — вариант A с fallback.  
  **Результат:** в `rag_chat.py` по умолчанию вызывается `build_context_by_question(question)`, флаг `--fixed` переключает на `build_context_fixed()`. README_RAG.md обновлён: описан вариант A по умолчанию и флаг `--fixed`, добавлена подсказка по `pip install openai` в venv.

---

## Критерии успеха

- Вопрос с упоминанием сущности из графа приводит к выборке, содержащей эту сущность и связанные с ней связи (в пределах лимитов).
- При отсутствии совпадений используется фиксированная выборка (fallback).
- `rag_chat.py` по умолчанию использует контекст по вопросу (вариант A).

---

## Ссылки

- План минимального RAG: [26-0213-1049_plan.md](26-0213-1049_plan.md)
- Резюме по нему: [26-0213-1049_plan_resume.md](26-0213-1049_plan_resume.md)
- **Резюме по данному плану:** [26-0215-1600_plan_resume.md](26-0215-1600_plan_resume.md)
- Задачи: [docs/tasks/TASKS.md](../tasks/TASKS.md)
