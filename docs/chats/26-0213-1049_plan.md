# План: минимальные шаги к RAG/диалогу (объём одного чата)

**Дата:** 2026-02-13, 10:49  
**Цель:** Достичь возможности диалога с LLM по данным графа ferag-prod (минимальный контур RAG).  
**Объём:** Работа, выполнимая в пределах примерно одного чата.  
**Предшественник:** [26-0210-1500_plan.md](26-0210-1500_plan.md) (цикл построения графа выполнен; резюме: [26-0210-1500_plan_resume.md](26-0210-1500_plan_resume.md)).

---

## Исходное состояние

- **ferag-prod** в Fuseki: 756 триплетов (онтология + сущности ferag#, описания, связи Relationship).
- SPARQL-доступ к графу есть (скрипт `verify_prod.py`, curl).
- LM Studio (или аналог) доступен для вызова LLM по API.
- Диалога «вопрос пользователя → ответ на основе графа» пока нет.

---

## Задача плана

Реализовать **минимальный контур**: вопрос (текст) → выборка релевантного контекста из ferag-prod → передача контекста и вопроса в LLM → ответ пользователю. Без обязательного развёртывания PostgreSQL/AGE/pgvector; без сложного Text-to-SPARQL на первом шаге (допустимы простые эвристики или фиксированные запросы).

---

## Шаги (в объёме одного чата)

### 1. Выборка контекста из ferag-prod

- Решить, что считать контекстом для одного запроса: например, сущности и их описания (ferag:description), либо триплеты вида (from, to, description) для связей, либо и то и другое с лимитом (например, топ-20 сущностей или топ-15 связей).
- Реализовать **простой способ** получения контекста по запросу:
  - **Вариант A:** SPARQL: сущности, у которых в `ferag:description` встречаются слова из вопроса (через REGEX или FILTER CONTAINS, если поддерживается), плюс их связи (Relationship) с соседями. Либо выдача «всего понемногу» (несколько сущностей и связей) при коротком вопросе.
  - **Вариант B:** без привязки к словам вопроса — для первого теста достать фиксированный набор сущностей и связей (например, первые 10–15 сущностей с описаниями и 10 связей), чтобы проверить цепочку вопрос → контекст → LLM → ответ.
- Реализация: скрипт на Python (requests к Fuseki SPARQL endpoint или rdflib + загрузка из Fuseki), на выходе — текстовое представление контекста (список «Сущность X: описание…», «Связь: A → B — описание…»).

### 2. Вызов LLM с контекстом и вопросом

- Вход: строка контекста (из шага 1), строка вопроса пользователя.
- Промпт: краткая инструкция («Ответь на вопрос пользователя, опираясь только на приведённый контекст из графа знаний. Если в контексте нет информации для ответа, так и скажи.») + контекст + вопрос.
- Вызов существующего API LLM (LM Studio: OpenAI-совместимый endpoint). Использовать уже имеющуюся настройку (base_url, модель).
- Результат: ответ модели в виде строки.

### 3. Сборка контура «вопрос → ответ»

- Один скрипт или небольшая программа (например, `graphrag-test/rag_chat.py` или аналог): аргумент командной строки или интерактивный ввод — вопрос; внутри: шаг 1 (получить контекст) → шаг 2 (вызвать LLM) → вывод ответа.
- Проверка: задать 1–2 вопроса по тематике корпуса (например, «Кто такой Alice Smith?», «Где работает Bob Johnson?») и убедиться, что ответ опирается на данные из графа.

### 4. Фиксация результата

- Кратко описать в плане или в README: как запускать, какой контекст используется, ограничения (например, «пока без семантического поиска по вопросу»).
- При успехе: зафиксировать, что минимальный RAG/диалог достигнут; рабочий процесс можно считать готовым вчерне (с оговоркой «минимальный диалог»). Дальше — улучшение ретривера, опционально проекции и векторный поиск.

---

## Критерии успеха

- Есть работающий скрипт (или команда), который по текстовому вопросу возвращает ответ LLM, сформированный на основе выборки из ferag-prod.
- На тестовых вопросах ответ отражает факты из графа (сущности, связи, описания).
- Документированы способ запуска и ограничения первой версии.

---

## Вне объёма данного плана (на потом)

- Умный Text-to-SPARQL или семантический поиск по вопросу.
- Векторный поиск (pgvector), проекции в PostgreSQL/AGE.
- Многошаговый диалог (история сообщений).
- LLM-ревизия слияния онтологий/триплетов.

---

## Ссылки

- План развёртывания (фазы 1–4 выполнены): [26-0210-1500_plan.md](26-0210-1500_plan.md)
- Резюме по нему: [26-0210-1500_plan_resume.md](26-0210-1500_plan_resume.md)
- Задачи 6.21, 6.22: [docs/tasks/TASKS.md](../tasks/TASKS.md)
- Проектная документация: [docs/project/PROJECT.md](../project/PROJECT.md)
